{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ödev 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Makine Öğrenimini nasıl tanımlarsınız?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makine öğrenmesi verilerden anlam çıkarmamıza yardımcı olur. Daha önceki deneyimleri (verileri); girdi ve çıktı değerlerini kullanarak aradaki ilişkiyi farklı optimizasyon süreçlerinden geçirerek bize yansıtır. Bu ilişkiyi makine öğrenmesinden model olarak çıktı alırız. Edindiğimiz bu modelin doğruluğunu ölçtükten ve uygun modeli bulduktan sonra; modelimiz üzerinden geleceğe yönelik olası durumları gözlemleyebiliriz. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Denetimli ve denetimsiz öğrenme arasındaki farklar nelerdir? Bunların her biri için örnek 3 algoritma belirtin.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Girdi ve çıktı değerleri üzerinde çalışan makine öğrenmesi kolu denetimli öğrenmedir. Sadece girdi verileri üzerinde çalışan ve girdi verilerini kümeleyip anlam çıkaran makine öğrenmesi koluna ise denetimsiz öğrenme diyoruz. Denetimli öğrenmeye örnek algoritmalar; lineer regresyon, lojistik regresyon, karar ağacı. Denetimsiz öğrenmeye örnek algoritmalar; k-means kümeleme, hiyerarşik kümeleme, centroid tabanlı kümeleme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Test ve doğrulama Seti nedir ve neden onları kullanmak istersiniz?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation seti train veri seti içerisinden seçilir. Train veri seti kullanılarak modelimiz belirlenir. Validation setinde model iyileştirilmeye çalışılır. Hiper parameterik (hyperparameter tuning) uygulamalar denenerek optimum katsayılar/ağırlıklar bulunmaya çalışılır. Büyük data setlerinde train verisi üzerinde çalışmak zor olacağı için doğrulanmış veri seti (validation set) kullanılır. Test veri setinde tahminler ile elimizdeki veriler karşılaştırılır. Test veri setinde öğrenilmiş model uygulanır; öncelikle target(y) değişkeni kaldırılıyor, ardından modelimize test verisindeki girdi değişkenleri eklenerek modelden target(y) değişkenlerini tahmin etmesi beklenir. Son olarak veri setimiz ile tahmin edilmiş veri setini karşılaştırarak modelimizin performansını ölçeriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Ana ön işleme adımları nelerdir? Bunları ayrıntılı olarak açıklayın. Verilerimizi neden hazırlamamız gerekiyor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yinelenen değerlerin tespit edilmesi, belirli bir veri setinin avantaj kazanmasının önüne geçmesi yönünden önemlidir. Dengesiz veriler, veriler arasında kıyaslama yaparken yanlış yönelimlerde bulunulması problemini ortaya çıkarır. Bu problemin önüne geçebilmek için kıyaslanan veri seti değerlerini olabildiğince eşit tutmamız gerekmektedir. Kayıp değerler, veri setimizdeki boş olan değerleri veri kümesini ortalama veya medyan değerleriyle doldururuz. Aykırı değer tespiti, veri setimiz içerisindeki olması gereken değerlere belirli mesafeden daha uzak olan verileri aykırı değer olarak isimlendiriyoruz. Standart sapma grafikleri, IQR hesaplması, izolasyon ormanı gibi farklı yöntemler kullanılarak tespit ediliyor ve veri kümesinden gerekli kodlar ile siliniyor. Özellik ölçeklendirme, iki farklı türü vardır; standardizasyon ve normalizasyon; standardizasyon veri kümemizin içerisindeki verileri standart sapması 1 ortalaması 0 olacak şekilde tekrar oluşturur. Özellik çıkarma, veri kümemiz içerisindeki birden fazla özelliği kullanarak bir özellik oluşturma işlemidir. Özellik kodlaması, nominal değerler için one-hot encoding yöntemiyle yapılır. kategorik değerler için binary bir tablo oluşturulur(var-yok). Ordinal(sıralı) değerler için yani azdan çoğa kategoriler ifade edilirken numaralar kullanılır. örneğin düşük için 0 orta için 1 yüksek için 2. Verilerimizi doğru modeli bulabilmek için hazırlamalıyız. Doğru model ise bize modelimiz eğitildiği konu üzerinde yeni veriyi çıkartabilmesi yönünden önemlidir. Veri gruplama, gözlem hatalarının etkilerini en aza indirmeyi hedefler. veri değerleri küçük aralıklar belirlenerek; bu aralıklar için hesaplanan genel bir değer ile değiştirilir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Kesikli ve sürekli değişkenleri nasıl keşfedebilir ve analiz edebilirsiniz?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kesikli değişkenleri kategorik değişkenler olarak ifade edebiliriz. kesikli değişkenler bağımsız değerler ile ifade edilir, bir şeylerin sayısıdır; sürekli değişken ise verilen aralıkta veya süreklilikte herhangi bir değer alır, bir şeylerin değişen ölçüsüdür. Örnek vermek gerekirse; ayrık değişken için bilgisayarınızın içerdiği çekirdek sayısı, kitaptaki sayfa sayısı, sürekli değişken için insanın zeka seviyesi, şirketlerin müşteri kaybetme potansiyelleri. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Aşağıda verilen grafiği analiz edin. (Çizim ve değişken türü nedir, dağıtımı kontrol edin ve onu nasıl ön işleyebileceğiniz konusunda yorum yapın.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Değişken türü sürekli değişkendir ve skewed dağılım gözükmektedir. Öncelikle tekrarlanan veri tespiti yapılabilir, veri setimizin komleksivitesini azaltmak için bu aşama uygulanabilir. Kayıp veriler varsa bunları medyan değerleri ile değiştirebiliriz."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
